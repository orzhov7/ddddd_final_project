---
title: "ddddd_final_project_markdown"
date: "9/16/2020"
output: html_document
---
```{r initialize_libraries}
library(janitor)
library(skimr)
library(tidyverse)
```

```{r zip_code_setup}
# This file was semicolon delimited due to location information.
# Removed non-Illinois zip codes, trimmed columns for timezone, daylight savings, and geolocation.

zip_codes <- read.csv("us_zip_codes.csv",sep=';') %>%
  filter(State == "IL") %>% 
  select(Zip, City, State, Latitude, Longitude) %>% 
  add_row(Zip = 60642, City = "Chicago", State = "IL", Latitude = 41.9036545, Longitude = -87.6577537)

# We found that the dataset was not complete for the City of Chicago, one zip code, for Goose Island, was missing. Adding it here.
zip_codes
```


```{r chicago_population_setup}
# This data source contains many empty columns we don't need, plus a full Chicago breakout by age.
# Neither of above is needed. Only need Zip and Population numbers. This data is from 2018.

chicago_population_zip_code <- read.csv("chicago_population_by_zip_code.csv") %>%
  filter(Geography.Type == "ZIP Code") %>%
   select(Zip = Geography, Population = Population...Total)

# Align Zip column data type with zip code list
chicago_population_zip_code$Zip <- as.integer(chicago_population_zip_code$Zip)
chicago_population_zip_code
```


```{r list_of_l_stops}
# This data contains station location and additional information about every L stop. Cleaning this data will require a few steps to get into the shape we need.

l_stops <- read.csv("list_of_l_stops.csv") %>%
  # Location string is made up of ("Latitude", "Longitude") so we need to first remove the parenthesis.
  mutate(New_Location = substring(Location, 2, nchar(Location) - 1)) %>%
  # We found an naming error in the data, this line replaces that error.
  mutate(Station_Name = ifelse(STATION_NAME == "95th/Ran Ryan", "95th/Dan Ryan", STATION_NAME)) %>%
  # We want to rename some station info for readability, and remove unneeded columns
  select(
      Map_ID = MAP_ID,
      Station_Name,
      Red_Line = RED,
      Blue_Line = BLUE,
      Green_Line = G,
      Brown_Line = BRN,
      Purple_Line = P,
      Purple_Line_Express = Pexp,
      Yellow_Line = Y,
      Pink_Line = Pnk,
      Orange_Line = O,
      New_Location) %>%
  # Finally, separate the Latitude and Longitude columns. More converting will be needed below.
  separate(New_Location, c("Latitude","Longitude"), ",")
l_stops
```

```{r l_stops_conversion}
# A lot of the above L Stop data was not in the proper form, we need logicals or doubles for line information and Latitude/Longitude. This code fulfills that need.

l_stops_conversion <- l_stops
l_stops_conversion$Red_Line <- as.logical(l_stops_conversion$Red_Line)
l_stops_conversion$Blue_Line <- as.logical(l_stops_conversion$Blue_Line)
l_stops_conversion$Green_Line <- as.logical(l_stops_conversion$Green_Line)
l_stops_conversion$Brown_Line <- as.logical(l_stops_conversion$Brown_Line)
l_stops_conversion$Purple_Line <- as.logical(l_stops_conversion$Purple_Line)
l_stops_conversion$Purple_Line_Express <- as.logical(l_stops_conversion$Purple_Line_Express)
l_stops_conversion$Yellow_Line <- as.logical(l_stops_conversion$Yellow_Line)
l_stops_conversion$Pink_Line <- as.logical(l_stops_conversion$Pink_Line)
l_stops_conversion$Orange_Line <- as.logical(l_stops_conversion$Orange_Line)
l_stops_conversion$Latitude <- as.numeric(l_stops_conversion$Latitude)
l_stops_conversion$Longitude <- as.numeric(l_stops_conversion$Longitude)
l_stops_conversion
```

```{r l_stops_duplicate_removal}
# The above code and data frame contain some duplicates, which we will need to collapse into single rows. What's happening here is that one stop could have split access for lines based on direction. We're not concerned with N/S or E/W, just what's available at the stop, when compared to the entry data.

l_stops_conversion_2 <- group_by(l_stops_conversion, Map_ID, Station_Name) %>% 
  summarise(Red_Line = any(Red_Line),
            Blue_Line = any(Blue_Line),
            Green_Line = any(Green_Line),
            Brown_Line = any(Brown_Line),
            Purple_Line = any(Purple_Line),
            Purple_Line_Express = any(Purple_Line_Express),
            Yellow_Line = any(Yellow_Line),
            Pink_Line = any(Pink_Line),
            Orange_Line = any(Orange_Line),
            Latitude = max(Latitude),
            Longitude = max(Longitude)
            )
l_stops_conversion_2
```
```{r create_line_group}
# Derive list of train stops by Map_ID for additional table.

line_group <- l_stops_conversion_2 %>% 
  ungroup() %>% 
  gather(Line_Name, Part_of_Line, -Map_ID, -Station_Name, -Latitude, -Longitude) %>% 
  filter(Part_of_Line == TRUE) %>% 
  select(Map_ID, Line_Name) %>% 
  arrange(Map_ID)
line_group
```
```{r trim_l_stops}
# Remove station information from stop location data.

l_stops_final <- l_stops_conversion_2 %>%
  ungroup() %>%
  select(Map_ID, Station_Name, Latitude, Longitude)
l_stops_final
```


```{r daily_entry_creation}
# This data was prepped beforehand to only include 2017-2019 ride entries. Full data set contained from 2000 and up, was too large to upload for sharing with team, trimmed data first using another set of R code.

daily_entries <- read.csv("daily_station_entries_2017_2019.csv") %>% 
  select(
      Map_ID = station_id,
      Ride_Date = date,
      Rides_Taken = rides)
daily_entries$Ride_Date <- as.Date(daily_entries$Ride_Date)
daily_entries
```

Begin Writing tables to MySQL!

```{r mysql_library_setup}
# Setup libraries for DB connection.

library(RMySQL)
library(keyring)
library(odbc)
```

```{r mysql_connection_setup_1}
# Setup connection variables.

service_mysql <- "r-mysql"
username_mysql <- "root"
```

```{r mysql_connection_setup_2, eval=FALSE}
# Setup login information.

keyring::key_set(service = service_mysql, username = username_mysql)
```

```{r mysql_connection_setup_3}
# Team created database with name "Final_Project_Schema"

con_final_project <- dbConnect(
  MySQL(),
  user = key_list(service = service_mysql)$username,
  password = key_get(
    service = service_mysql,
    username = key_list(service = service_mysql)$username
  ),
  dbname = "final_project_schema",
  host = "localhost"
)
```

```{sql connection=con_final_project}
USE final_project_schema
```

```{sql connection=con_final_project}
SHOW TABLES
```
```{sql connection=con_final_project}
SHOW VARIABLES LIKE 'local_infile';
```
```{sql connection=con_final_project}
SET GLOBAL local_infile = 1;
```

```{r push_population_to_sql}
# Push population data to MySQL DB

chicago_population_zip_code %>%
  # Note: the . in the `dbWriteTable` call represents the dataframe
  # Normally %>% makes the data the first argument of the next function call
  # But in this case the first argument to dbWritetable is `conn`
  # So we defer the data to the third argument in `dbWritetable` by using the .
  dbWriteTable(
    # connection object
    conn = con_final_project,
    # table name
    name = "chicago_population",
    # the dataframe
    value = .,
    # overwrite the table; we could also use append = TRUE
    overwrite = TRUE
  )
```


```{r push_daily_entries_to_sql}
# Push daily_entries data to MySQL DB

daily_entries %>%
  # Note: the . in the `dbWriteTable` call represents the dataframe
  # Normally %>% makes the data the first argument of the next function call
  # But in this case the first argument to dbWritetable is `conn`
  # So we defer the data to the third argument in `dbWritetable` by using the .
  dbWriteTable(
    # connection object
    conn = con_final_project,
    # table name
    name = "daily_entries",
    # the dataframe
    value = .,
    # overwrite the table; we could also use append = TRUE
    overwrite = TRUE
  )
```
```{r push_line_group_to_sql}
# Push line_group data to MySQL DB

line_group %>%
  # Note: the . in the `dbWriteTable` call represents the dataframe
  # Normally %>% makes the data the first argument of the next function call
  # But in this case the first argument to dbWritetable is `conn`
  # So we defer the data to the third argument in `dbWritetable` by using the .
  dbWriteTable(
    # connection object
    conn = con_final_project,
    # table name
    name = "line_group",
    # the dataframe
    value = .,
    # overwrite the table; we could also use append = TRUE
    overwrite = TRUE
  )
```
```{r push_l_stop_to_sql}
# Push l_stops data to MySQL DB

l_stops_final %>%
  # Note: the . in the `dbWriteTable` call represents the dataframe
  # Normally %>% makes the data the first argument of the next function call
  # But in this case the first argument to dbWritetable is `conn`
  # So we defer the data to the third argument in `dbWritetable` by using the .
  dbWriteTable(
    # connection object
    conn = con_final_project,
    # table name
    name = "l_stops",
    # the dataframe
    value = .,
    # overwrite the table; we could also use append = TRUE
    overwrite = TRUE
  )
```
```{r push_zip_codes_to_sql}
# Push zip_codes data to MySQL DB

zip_codes %>%
  # Note: the . in the `dbWriteTable` call represents the dataframe
  # Normally %>% makes the data the first argument of the next function call
  # But in this case the first argument to dbWritetable is `conn`
  # So we defer the data to the third argument in `dbWritetable` by using the .
  dbWriteTable(
    # connection object
    conn = con_final_project,
    # table name
    name = "zip_codes",
    # the dataframe
    value = .,
    # overwrite the table; we could also use append = TRUE
    overwrite = TRUE
  )
```


```{r create_mapping_query}
# Using data stored in MySQL to create a mapping table for distance from zip codes to each station.

# Feeding SQL query to make a data frame where robust calculations can be done.

stops_and_zips_query <- "SELECT
  l_stops.Map_ID,
  l_stops.Longitude AS Stop_Longitude,
  l_stops.Latitude AS Stop_Latitude,
  zip_codes.Zip,
  zip_codes.Longitude AS Zip_Longitude,
  zip_codes.Latitude AS Zip_Latitude
FROM l_stops
CROSS JOIN zip_codes
WHERE zip_codes.City = 'Chicago'"

# Loading query into data frame.

stops_and_zips <- dbGetQuery(con_final_project, stops_and_zips_query) %>%
  as_tibble()
stops_and_zips
```

```{r calculate_distance}

# The below code is known as the Spherical Law of Cosines which calculates the shortest distance between two points on a sphere. We are assuming the Earth is a perfect sphere, which is fine given that most distances are under a few miles. Larger distances would need to take additional factors into account.
# This code assumes that the Latitudes and Longitudes are in radians and the output is in kilometers. We will apply conversion factors as well for our audience.
# acos(sin(lat1)*sin(lat2) + cos(lat1)*cos(lat2) * cos(long2-long1)) * R)

# Factor to convert degrees to radians
convert_radians <- pi/180
# Earth radius in km
earth_radius <- 6371
# Factor to convert to miles
convert_miles <- .6213712

stops_and_zips_2 <- stops_and_zips %>% 
  mutate(Distance = convert_miles*acos(sin(Stop_Latitude*convert_radians)*sin(Zip_Latitude*convert_radians) + cos(Stop_Latitude*convert_radians)*cos(Zip_Latitude*convert_radians) * cos(Zip_Longitude*convert_radians - Stop_Longitude*convert_radians)) * earth_radius) %>% 
  select(Map_ID, Zip, Distance)
stops_and_zips_2
```

```{r push_mapping_to_sql}
# Push mapping data to MySQL DB

stops_and_zips_2 %>%
  # Note: the . in the `dbWriteTable` call represents the dataframe
  # Normally %>% makes the data the first argument of the next function call
  # But in this case the first argument to dbWritetable is `conn`
  # So we defer the data to the third argument in `dbWritetable` by using the .
  dbWriteTable(
    # connection object
    conn = con_final_project,
    # table name
    name = "stations_to_zips",
    # the dataframe
    value = .,
    # overwrite the table; we could also use append = TRUE
    overwrite = TRUE
  )
```